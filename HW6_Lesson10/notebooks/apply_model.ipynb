{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, IntegerType, LongType, StringType}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current spark version is 2.4.4\n"
     ]
    }
   ],
   "source": [
    "println(s\"Current spark version is ${spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputStreamPath = /home/jovyan/data/events-stream\n",
       "modelPath = /home/jovyan/models/spark-ml-model\n",
       "dataSchema = StructType(StructField(tweet,StringType,true))\n",
       "inputDF = [tweet: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[tweet: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val inputStreamPath = \"/home/jovyan/data/events-stream\"\n",
    "val modelPath = \"/home/jovyan/models/spark-ml-model\"\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"tweet\", StringType)\n",
    "\n",
    "val inputDF = spark\n",
    "    .readStream\n",
    "    .schema(dataSchema)\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .json(inputStreamPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "inputDF.writeStream\n",
    "      .format(\"console\")\n",
    "      .outputMode(\"append\")\n",
    "      .start()             // Start the computation\n",
    "      .awaitTermination()  // Wait for the computation to terminate\n",
    "\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "getProbability = UserDefinedFunction(<function1>,DoubleType,Some(List(org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7)))\n",
       "getTimestamp = UserDefinedFunction(<function0>,LongType,Some(List()))\n",
       "loadedModel = pipeline_d0f6df2ac549\n",
       "dataSchema = StructType(StructField(tweet,StringType,true), StructField(prediction,IntegerType,true), StructField(clean_probability,LongType,true), StructField(TS,LongType,true))\n",
       "predDF = [tweet: string, prediction: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.execution.streamin..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "57\n",
      "73\n",
      "86\n",
      "91\n",
      "106\n",
      "127\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import java.time.Instant\n",
    "\n",
    "val getProbability = udf((prediction: org.apache.spark.ml.linalg.Vector) => prediction(1))\n",
    "val getTimestamp = udf(() => Instant.now.getEpochSecond )\n",
    "\n",
    "val loadedModel = PipelineModel.load(\"/home/jovyan/models/spark-ml-model\")\n",
    "\n",
    "val dataSchema = new StructType()\n",
    "    .add(\"tweet\", StringType)\n",
    "    .add(\"prediction\", IntegerType)\n",
    "    .add(\"clean_probability\", LongType)\n",
    "    .add(\"TS\", LongType)\n",
    "\n",
    "var predDF = Seq.empty[(String, Int, Long, Long)].toDF(\"tweet\", \"prediction\", \"clean_probability\", \"TS\")\n",
    "\n",
    "inputDF.writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long) =>\n",
    "    \n",
    "    val predictionsDF = loadedModel.transform(batchDF)\n",
    "    val now_minus_10 = getTimestamp() - 10\n",
    "    val resDF = predictionsDF.select($\"tweet\", $\"prediction\", getProbability($\"probability\").alias(\"clean_probability\"), getTimestamp().alias(\"TS\"))\n",
    "        \n",
    "    predDF = predDF.union(resDF)\n",
    "    //resDF.show(1000)\n",
    "    println(predDF.count()) //.filter($\"TS\" >= now_minus_10)    \n",
    "    //predDF.filter($\"TS\" >= now_minus_10).groupBy(\"prediction\").count().show()\n",
    "}.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
