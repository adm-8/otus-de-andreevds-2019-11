# Homework6 - OTUS-DS-2019-11 

## Обучение моделей ML

### Цели
В результате данного ДЗ вы научитесь обучаю свою собственную простейшую модель на Apache Spark и применять ее к стриминговым данным.

### Описание 
Внимание!

Из необходимого для успешной работы всей инфраструктурной обвязки:
- docker
- Makefile (в противном случае команды можно запускать руками, копируя их из Makefile).

Для решения данного задания необходимо:
1. Сделать форк от master из репозитория https://github.com/OtusTeam/data-engineer
2. Перейти в папку spark_ml (командой в консоли: cd spark_ml)
3. Запустить докер-контейнер с jupyter notebook
4. Последовательно выполнить все ноутбуки в Readme.md (построить модель на Python + scikit-learn, построить модель на Apache Spark)
5. При построении модели на Apache Spark необходимо в качестве классификатора необходимо использовать вместо LogisticRegression на RandomForest.
Документация по API представлена здесь - https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier. Обратите внимание что необходимо использовать новое API (spark.ml).

6. После построения модели и ее сохранения на диск, необходимо запустить стриминг из ноутбука (tweet_feeder).
7. Далее необходимо применить модель в streaming mode. Заготовка для имплементации находится в ноутбуке (apply_model). В базовом подходе достаточно просто выводить результат применения модели. Обратите внимание что в качестве результата мы хотим видеть в отдельной колонке вероятность негативного твита (внутри поля probability представлен вектор из двух значений, нам нужна отдельная колонка с последним значением). Напишите udf который будет доставать эту колонку отдельно.
8. Предоставьте корректно работающий форк на проверку.

Advanced:
- Попробуйте выводить статистику по количеству "негативных" и "позитивных" твитов за последние 10 секунд скользящим окном.
Критерии оценки: 1.Факт совершения действия - форк предоставлен на проверку

+1 балл

2. Степень выполнения ДЗ

+3 балл - streaming job выводит результаты скоринга
+4 балла - streaming job выводит результаты скоринга и написан udf который выводит последнее значение из поля probability в виде отдельной колонки.
Рекомендуем сдать до: 26.01.2020


### полезные ссылки
[Дока по SparkML Random Forest Classifier](https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier)

[Дока по TFIDF](https://spark.apache.org/docs/2.2.0/ml-features.html#tf-idf)
